{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import time, sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.transfermarkt.com\"\n",
    "\n",
    "class League:\n",
    "\tdef __init__( self, name, url, scraper):\n",
    "\t\tself.LeagueName = name\n",
    "\t\tsoup = scraper(url)\n",
    "\t\tteamsTable = soup.find(\"table\", class_=\"items\")\n",
    "\t\tteamUrls = teamsTable.find_all(\"a\", class_=\"vereinprofil_tooltip\", id=re.compile(\"\\d+\"))[::2]\n",
    "\t\tteamUrls = [BASE_URL + teamUrl[\"href\"] for teamUrl in teamUrls]\n",
    "\t\tself.TeamsData = [ Team(teamUrl, self.LeagueName, scraper) for teamUrl in teamUrls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.transfermarkt.com\"\n",
    "\n",
    "\n",
    "class Team:\n",
    "\tdef __init__( self, url, name, scraper):\n",
    "\t\tself.LeagueName = name\n",
    "\t\tsoup = scraper(url)\n",
    "\t\t#reading player table and filtering for offensive players\n",
    "\t\tplayerTable = soup.find(\"table\", class_=\"items\")\n",
    "\t\tplayers = playerTable.find_all(\"a\", class_=\"spielprofil_tooltip\")[::2]\n",
    "# \t\toffensivePlayers = filter( Team.isStrikerOrWinger, players)\n",
    "\t\tPlayersUrls = [BASE_URL + player[\"href\"] for player in players]\n",
    "\t\t#self.PlayerData = [PlayerProfile( playerUrl, scraper) for playerUrl in offensivePlayersUrls]\n",
    "\t\tself.PlayersData = []\n",
    "\t\tfor playerUrl in PlayersUrls:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tNewPlayerProfile = PlayerProfile( playerUrl, scraper)\n",
    "\t\t\t\tNewPlayerProfile.PlayerData[\"current league\"] = self.LeagueName\n",
    "\t\t\t\tself.PlayersData.append( NewPlayerProfile)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef isStrikerOrWinger( player):\n",
    "\t\tposition = player.find_next(\"tr\").text.strip().lower()\n",
    "\t\treturn \"wing\" in position or \"centre-forward\" in position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "CURRENT_YEAR = 19\n",
    "N_SEASON_HISTORY = 5\n",
    "\n",
    "\n",
    "class PlayerProfile:\n",
    "\tdef __init__(self, playerUrl, pageScraper):\n",
    "\t\turlPerfPage = playerUrl.replace(\"profil\",\"leistungsdatendetails\")\n",
    "\t\tsoup = pageScraper( playerUrl)\n",
    "\n",
    "\t\tplayerAttributes = {}\n",
    "\n",
    "\t\t#scraping profile page information\n",
    "\t\tplayerAttributes[\"name\"] = soup.find(\"div\", class_=\"dataMain\").find(\"h1\").text\n",
    "\t\tStoredAttributes = [\"Age:\", \"Height:\", \"Nationality:\", \"Position:\", \"Foot:\", \"Current club:\"]\n",
    "\t\tfor entry in soup.find(\"table\", class_=\"auflistung\").find_all(\"th\"):\n",
    "\t\t\tkey = entry.text.strip()\n",
    "\t\t\tval = entry.find_next_sibling().text\n",
    "\t\t\tif key in StoredAttributes:\n",
    "\t\t\t\tplayerAttributes[ key[:-1].lower()] = val.strip()\n",
    "\t\t#cleaning some entries\n",
    "\t\tif \"height\" in playerAttributes:\n",
    "\t\t\t#converting height in meters str to cm int \n",
    "\t\t\tmeter, centimeters = re.search(\"(\\d),(\\d+)\",playerAttributes[\"height\"]).groups()\n",
    "\t\t\tplayerAttributes[\"height\"] = int(meter)*100 + int(centimeters)\n",
    "\t\tif \"nationality\" in playerAttributes:\n",
    "\t\t\tif \"\\xa0\" in playerAttributes[\"nationality\"]:\n",
    "\t\t\t\tplayerAttributes[\"nationality\"] = playerAttributes[\"nationality\"].replace(\"\\xa0\", \" \")\n",
    "\t\tif \"position\" in playerAttributes:\n",
    "\t\t\tplayerAttributes[\"position\"] = \"CF\" if \"Centre-Forward\" in playerAttributes[\"position\"] else \"W\"\n",
    "\t\tif \"age\" in playerAttributes:\n",
    "\t\t\tplayerAttributes[\"age\"] = int( playerAttributes[\"age\"])\n",
    "\n",
    "\t\t#scraping performance page information\n",
    "\t\tsoup = pageScraper(urlPerfPage)\n",
    "\t\tperformanceColumns = (\"season\", \"games\", \"goals\", \"assists\", \"minutes\")\n",
    "\t\tperformanceRows = pd.DataFrame( {col:[] for col in performanceColumns})\n",
    "\t\tfor row in soup.find(\"div\", class_=\"responsive-table\").find(\"tbody\").find_all(\"tr\"):\n",
    "\t\t\t#try:\n",
    "\t\t\trowContents = PlayerProfile.readRow( row)\n",
    "\t\t\t#except:\n",
    "\t\t\t#\t print( row)\n",
    "\t\t\t#else:\n",
    "\t\t\t#\t pass\n",
    "\t\t\tyear = rowContents[0]\n",
    "\t\t\tif re.match( \"\\d{4}\", year):\n",
    "\t\t\t\tyear = int( year[2:])\n",
    "\t\t\t\tyear = \"%02d/%02d\" %(year-1, year)\n",
    "\t\t\t\trowContents[0] = year\n",
    "\t\t\tif not re.match( \"\\d{2}\\/\\d{2}\", year):\n",
    "\t\t\t\traise ValueError(\"Wrong format for played year\")\n",
    "\t\t\tif int( year[:2]) < CURRENT_YEAR - N_SEASON_HISTORY:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t#print( rowContents)\n",
    "\t\t\tperformanceRows = performanceRows.append( {col:val for col, val in zip(performanceColumns, rowContents)}, ignore_index=True)\n",
    "\t\tperformanceDF = performanceRows.groupby(\"season\").sum()\n",
    "\t\t#converting to serie\n",
    "\t\tperformanceSeries = pd.Series( {\"%s %s\" %(row, col): performanceDF[col][row] for row in performanceDF.index for col in performanceDF.columns})\n",
    "\t\t\n",
    "\t\tself.PlayerData = pd.Series( playerAttributes).append( performanceSeries)\n",
    "\t\tprint( \"\\t%s done\" %self.PlayerData[\"name\"])\n",
    "\t\t\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"Performance profile for %s\" % self.PlayerData[\"name\"]\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn \"< profile of %s >\" % self.PlayerData[\"name\"]\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef readRow( row):\n",
    "\t\tcells = row.find_all( \"td\")\n",
    "\t\tcells = list( map( lambda x : x.text.strip(), cells))\n",
    "\t\tyear = cells[0]\n",
    "\t\tgames_played = cells[4]\n",
    "\t\tgoals_scored = cells[6]\n",
    "\t\tassists = cells[7]\n",
    "\t\tminutes_played = cells[-1]\n",
    "\t\tgames_played = int(games_played) if games_played != \"-\" else 0\n",
    "\t\tgoals_scored = int(goals_scored) if goals_scored != \"-\" else 0\n",
    "\t\tassists = int(assists) if assists != \"-\" else 0\n",
    "\t\tminutes_played = int( minutes_played[:-1].replace(\".\",\"\")) if minutes_played != \"-\" else 0\n",
    "\t\treturn [year, games_played, goals_scored, assists, minutes_played]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping the Premier League...\n",
      "\tAymeric Laporte done\n"
     ]
    }
   ],
   "source": [
    "N_LEAGUES = 1 #keeping the top N leagues\n",
    "LEAGUES_URL = \"https://www.transfermarkt.com/wettbewerbe/europa/wettbewerbe\"\n",
    "BASE_URL = \"https://www.transfermarkt.com\"\n",
    "\n",
    "DELAY_BETWEEN_QUERIES = 0 #min delay in seconds spacing http queries\n",
    "class PageScraper():\n",
    "    def __init__(self ):\n",
    "        self.opener = urllib.request.build_opener()\n",
    "        self.opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "        self.lastQuery = -float(\"inf\")\n",
    "    def readUrl( self, url_):\n",
    "        presentTime = time() - self.lastQuery - DELAY_BETWEEN_QUERIES\n",
    "        if presentTime < 0:\n",
    "            sleep( abs(presentTime))\n",
    "        inData = self.opener.open(url_)\n",
    "        content = inData.read()\n",
    "        self.lastQuery = time()\n",
    "        return bs(content, \"html.parser\")\n",
    "    def __call__( self, url_):\n",
    "        return self.readUrl( url_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tscraper = PageScraper()\n",
    "\tsoup = scraper( LEAGUES_URL)\n",
    "\tLeagueTables = soup.find(\"table\", class_=\"items\").find(\"tbody\")\n",
    "\tLeagues = LeagueTables.find_all(\"a\", href=re.compile(\"wettbewerb/[A-Z]{2}1\"), title=re.compile(\"\\w\"))\n",
    "\tLeagues = Leagues[:N_LEAGUES]\n",
    "\tLeagueUrlDic = { league.text : BASE_URL + league[\"href\"] for league in Leagues}\n",
    "\tLeaguesData = []\n",
    "\tfor leagueName, leagueUrl in LeagueUrlDic.items():\n",
    "\t\tprint( \"Scraping the %s...\" %leagueName)\n",
    "\t\tLeaguesData.append( League( leagueName, leagueUrl, scraper))\n",
    "\n",
    "\t#flattening all players information to pandas.DataFrame and exporting to csv\n",
    "\tPlayerProfiles = [player.PlayerData for league in LeaguesData for team in league.TeamsData for player in team.PlayersData]\n",
    "\tdf = pd.DataFrame( PlayerProfiles)\n",
    "\tdf.to_csv(\"transfer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
